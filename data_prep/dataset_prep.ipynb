{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb9d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a85d7165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 112, 113)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the full training data\n",
    "train_df_full = pd.read_csv('~/stanford-rna-3d-folding/train_sequences.csv')\n",
    "\n",
    "subset_fraction = 0.4  # This will give 40% of the original data\n",
    "sampled_df = train_df_full.sample(frac=subset_fraction, random_state=42).reset_index(drop=True)\n",
    "\n",
    "train_fraction = 1/3\n",
    "test_fraction = 0.5 # Of the remaining 2/3, take half for test\n",
    "\n",
    "train_df = sampled_df.sample(frac=train_fraction, random_state=42)\n",
    "remaining_df = sampled_df.drop(train_df.index)\n",
    "\n",
    "test_df = remaining_df.sample(frac=test_fraction, random_state=42)\n",
    "validation_df = remaining_df.drop(test_df.index) # The rest is for validation (10% of original)\n",
    "\n",
    "len(train_df), len(test_df), len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5bfedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two cif directories, sample the relevant files from the full cif directory\n",
    "# this allows us to later use the preprocessing script to generate the datasets\n",
    "import os\n",
    "import shutil\n",
    "base_dir = os.path.expanduser('~/stanford-rna-3d-folding/')\n",
    "os.makedirs(os.path.join(base_dir, 'cifs'), exist_ok=True)\n",
    "assert os.path.exists(os.path.join(base_dir, 'cifs'))\n",
    "os.makedirs(os.path.join(base_dir, 'train_cif'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'test_cif'), exist_ok=True)\n",
    "os.makedirs(os.path.join(base_dir, 'val_cif'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4532fd06-206b-468d-8099-cceda653272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8672/8672 [00:31<00:00, 278.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# cp all files from PDB_RNA to cifs if ends with cif\n",
    "from tqdm import tqdm\n",
    "for f in tqdm(os.listdir(os.path.join(base_dir, 'PDB_RNA'))):\n",
    "    if not f.endswith('.cif'): continue\n",
    "    shutil.copy(os.path.join(base_dir, 'PDB_RNA', f), os.path.join(base_dir, 'cifs', f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc3fd170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:00, 329.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for 6DU5_B, skipping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [00:00, 428.88it/s]\n",
      "112it [00:00, 338.20it/s]\n",
      "113it [00:00, 395.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i, row in tqdm(train_df.iterrows()):\n",
    "    try:\n",
    "        shutil.copy(os.path.join(base_dir, 'cifs', (row['target_id']).lower().split('_')[0] + '.cif'), os.path.join(base_dir, 'train_cif'))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {row['target_id']}, skipping...\")\n",
    "\n",
    "for i, row in tqdm(test_df.iterrows()):\n",
    "    try:\n",
    "        shutil.copy(os.path.join(base_dir, 'cifs', (row['target_id']).lower().split('_')[0] + '.cif'), os.path.join(base_dir, 'test_cif'))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {row['target_id']}, skipping...\")\n",
    "\n",
    "for i, row in tqdm(validation_df.iterrows()):\n",
    "    try:\n",
    "        shutil.copy(os.path.join(base_dir, 'cifs', (row['target_id']).lower().split('_')[0] + '.cif'), os.path.join(base_dir, 'val_cif'))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for {row['target_id']}, skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ea7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
